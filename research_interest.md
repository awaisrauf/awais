My research interests lie at the intersection of optimization and reinforcement learning.
In my Bachelor's, I have developed a scalable second-order method applicable to the online stochastic optimization setting.
We applied this technique to locomotion problems of bio-inspired robotic quadrupeds.
In the first year of my PhD, I focused on understanding and reducing the variance of policy gradient estimators.
For the first project, we derived bounds on the variance of REINFORCE in the LQR setting.
As a second project, we developed a new stochastic gradient estimator with guaranteed asymptotic convergence with constant step-sizes.
Nowadays, I am interested in the question of meta-learning and how to efficiently discover policies that are suitable for a wide-range of different tasks.

I am also a big fan of open-source software and maintain an experiment management package (randopt.ml) and a reinforcement learning library (cherry-rl.net).
